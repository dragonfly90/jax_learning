{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3544e2cd",
   "metadata": {},
   "source": [
    "Scan and Control Flow: Loops and Conditionals in JAX\n",
    "=====================================================\n",
    "\n",
    "Key concepts:\n",
    "- jax.lax.scan: Efficient loop primitive (like fold/reduce with carry).\n",
    "- jax.lax.cond: Conditional execution (if/else).\n",
    "- jax.lax.while_loop: While loops compatible with jit.\n",
    "- jax.lax.fori_loop: For loops compatible with jit.\n",
    "- Python control flow doesn't work inside jit — use these instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2121b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eb17b6",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619f016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Why not Python loops inside jit? ----\n",
    "# Python for/if are traced once at compile time — they can't depend on values.\n",
    "\n",
    "# This WORKS but unrolls the loop (slow compilation for large N):\n",
    "@jax.jit\n",
    "def python_loop(x):\n",
    "    for i in range(5):  # unrolled at trace time\n",
    "        x = x + 1.0\n",
    "    return x\n",
    "\n",
    "print(\"Python loop:\", python_loop(0.0))  # 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8d8eb3",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b38357",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. jax.lax.scan — The workhorse ----\n",
    "# scan(f, carry, xs) applies f sequentially, threading a carry state.\n",
    "# f(carry, x) -> (new_carry, output)\n",
    "\n",
    "def scan_step(carry, x):\n",
    "    \"\"\"Running sum.\"\"\"\n",
    "    total = carry + x\n",
    "    return total, total  # (new_carry, output_to_stack)\n",
    "\n",
    "xs = jnp.array([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "final_carry, all_sums = jax.lax.scan(scan_step, 0.0, xs)\n",
    "print(f\"\\nScan running sum: {all_sums}\")        # [1, 3, 6, 10, 15]\n",
    "print(f\"Final carry: {final_carry}\")             # 15.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c25a7b",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e7bbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Scan for RNN-style computation ----\n",
    "\n",
    "def rnn_step(h, x):\n",
    "    \"\"\"Simple RNN cell: h_new = tanh(W_h @ h + W_x @ x).\"\"\"\n",
    "    W_h = jnp.eye(4) * 0.5\n",
    "    W_x = jnp.ones((4, 3)) * 0.1\n",
    "    h_new = jnp.tanh(W_h @ h + W_x @ x)\n",
    "    return h_new, h_new\n",
    "\n",
    "# Process a sequence of length 10, feature dim 3\n",
    "key = jax.random.PRNGKey(0)\n",
    "sequence = jax.random.normal(key, (10, 3))\n",
    "h0 = jnp.zeros(4)\n",
    "\n",
    "final_h, all_h = jax.lax.scan(rnn_step, h0, sequence)\n",
    "print(f\"\\nRNN output shape: {all_h.shape}\")  # (10, 4)\n",
    "print(f\"Final hidden state: {final_h}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36c2a05",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15373a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Scan for training loops ----\n",
    "# Avoids Python loop overhead, compiles the entire training as one XLA program\n",
    "\n",
    "def make_train_step(loss_fn):\n",
    "    @jax.jit\n",
    "    def scan_train(params, data):\n",
    "        def step(params, batch):\n",
    "            x, y = batch\n",
    "            loss, grads = jax.value_and_grad(loss_fn)(params, x, y)\n",
    "            new_params = jax.tree.map(lambda p, g: p - 0.01 * g, params, grads)\n",
    "            return new_params, loss\n",
    "        return jax.lax.scan(step, params, data)\n",
    "    return scan_train\n",
    "\n",
    "def mse_loss(params, x, y):\n",
    "    pred = x @ params['w'] + params['b']\n",
    "    return jnp.mean((pred - y) ** 2)\n",
    "\n",
    "params = {'w': jnp.zeros((3, 1)), 'b': jnp.float32(0.0)}\n",
    "# Simulate 20 training steps with batched data\n",
    "X_batches = jax.random.normal(key, (20, 8, 3))\n",
    "Y_batches = jax.random.normal(key, (20, 8, 1))\n",
    "\n",
    "train_fn = make_train_step(mse_loss)\n",
    "final_params, losses = train_fn(params, (X_batches, Y_batches))\n",
    "print(f\"\\nTraining losses (first 5): {losses[:5]}\")\n",
    "print(f\"Training losses (last 5): {losses[-5:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c17e14",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabac6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. jax.lax.cond — Conditional execution ----\n",
    "# cond(pred, true_fn, false_fn, *operands)\n",
    "\n",
    "@jax.jit\n",
    "def abs_value(x):\n",
    "    return jax.lax.cond(\n",
    "        x >= 0,\n",
    "        lambda x: x,       # true branch\n",
    "        lambda x: -x,      # false branch\n",
    "        x\n",
    "    )\n",
    "\n",
    "print(f\"\\nabs(3.0) = {abs_value(3.0)}\")\n",
    "print(f\"abs(-5.0) = {abs_value(-5.0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e04b7a",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e3267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. jax.lax.while_loop ----\n",
    "# while_loop(cond_fn, body_fn, init_val)\n",
    "\n",
    "@jax.jit\n",
    "def newton_sqrt(x):\n",
    "    \"\"\"Compute sqrt(x) via Newton's method.\"\"\"\n",
    "    def cond_fn(state):\n",
    "        guess, _ = state\n",
    "        return jnp.abs(guess * guess - x) > 1e-6\n",
    "\n",
    "    def body_fn(state):\n",
    "        guess, i = state\n",
    "        guess = (guess + x / guess) / 2.0\n",
    "        return (guess, i + 1)\n",
    "\n",
    "    guess, n_iters = jax.lax.while_loop(cond_fn, body_fn, (x / 2.0, 0))\n",
    "    return guess, n_iters\n",
    "\n",
    "result, iters = newton_sqrt(2.0)\n",
    "print(f\"\\nsqrt(2) = {result:.6f} (in {iters} iterations)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9ff40f",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78342fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. jax.lax.fori_loop ----\n",
    "# fori_loop(lower, upper, body_fn, init_val)\n",
    "\n",
    "@jax.jit\n",
    "def power(base, n):\n",
    "    \"\"\"Compute base^n using fori_loop.\"\"\"\n",
    "    def body(i, val):\n",
    "        return val * base\n",
    "    return jax.lax.fori_loop(0, n, body, 1.0)\n",
    "\n",
    "print(f\"\\n2^10 = {power(2.0, 10)}\")\n",
    "print(f\"3^5 = {power(3.0, 5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbb598a",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98088ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. jax.lax.switch — Multi-way branch ----\n",
    "# switch(index, branches, *operands)\n",
    "\n",
    "@jax.jit\n",
    "def activation(x, kind):\n",
    "    \"\"\"Apply different activations based on kind index.\"\"\"\n",
    "    return jax.lax.switch(\n",
    "        kind,\n",
    "        [\n",
    "            lambda x: x,                    # 0: identity\n",
    "            lambda x: jax.nn.relu(x),        # 1: ReLU\n",
    "            lambda x: jnp.tanh(x),           # 2: tanh\n",
    "            lambda x: jax.nn.sigmoid(x),     # 3: sigmoid\n",
    "        ],\n",
    "        x\n",
    "    )\n",
    "\n",
    "x = jnp.array([-1.0, 0.0, 1.0])\n",
    "for i, name in enumerate(['identity', 'relu', 'tanh', 'sigmoid']):\n",
    "    print(f\"  {name}({x}) = {activation(x, i)}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
